{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vehicle Detection\n",
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.version\n",
    "sys.version_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing some useful packages\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import glob\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "from PIL import Image\n",
    "from PIL import ImageFont\n",
    "from PIL import ImageDraw \n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from scipy.stats import linregress\n",
    "from scipy.ndimage.measurements import label\n",
    "from skimage.feature import hog\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import udacity lesson code (functions)\n",
    "import udacity_features as uf\n",
    "import udacity_window as uw\n",
    "import udacity_plot3d as u3d\n",
    "import udacity_heat as uh\n",
    "import udacity_find_cars as ufc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import previous projects functions\n",
    "import car_roi\n",
    "import car_hough\n",
    "import car_roi\n",
    "import car_camera\n",
    "import car_histogram\n",
    "import car_warp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Major Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### TODO: Tweak these parameters and see how the results change.\n",
    "#color_space = 'HSV' # Can be RGB, HSV, LUV, HLS, YUV, YCrCb\n",
    "color_spaces = [\"HSV\", \"YCrCb\", \"YUV\"] #[\"RGB\", \"HSV\", \"LUV\", \"HLS\", \"YUV\", \"YCrCb\"]\n",
    "orient = 11  # HOG orientations\n",
    "pix_per_cell = 8 # HOG pixels per cell\n",
    "cell_per_block = 0 # HOG cells per block\n",
    "hog_channel = 0 # Can be 0, 1, 2, or \"ALL\"\n",
    "spatial_size = (32,32) # Spatial binning dimensions\n",
    "hist_bins = 16    # Number of histogram bins\n",
    "spatial_feat = True # Spatial features on or off\n",
    "hist_feat = True # Histogram features on or off\n",
    "hog_feat = True # HOG features on or off\n",
    "y_start_stop = [None, None] # Min and max in y to search in slide_window()\n",
    "\n",
    "CONST_CROP_X1 = 400\n",
    "CONST_CROP_X2 = 656\n",
    "CONST_CROP_Y1 = 300\n",
    "CONST_CROP_Y2 = 1280"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are some helper functions. Some of them are based on the first line lanes \n",
    ":)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw_boxes(img, bboxes, color=(0, 0, 255), thick=6):\n",
    "    # make a copy of the image\n",
    "    draw_img = np.copy(img)\n",
    "    \n",
    "    for bbox in bboxes:\n",
    "        cv2.rectangle(draw_img, bbox[0], bbox[1], color, thick)\n",
    "    # draw each bounding box on your image copy using cv2.rectangle()\n",
    "    # return the image copy with boxes drawn\n",
    "    return draw_img # Change this line to return image copy with boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a function that takes an image and a list of templates as inputs\n",
    "# then searches the image and returns the a list of bounding boxes \n",
    "# for matched templates\n",
    "def find_matches(img, template_list):\n",
    "    draw_img = img.copy() # Make a copy of the image to draw on\n",
    "    bbox_list = [] # Define an empty list to take bbox coords\n",
    "    \n",
    "    for it in template_list: # Iterate through template list\n",
    "        tmp = mpimg.imread(it) # Read in templates one by one\n",
    "        res = cv2.matchTemplate(draw_img, tmp, cv2.TM_CCOEFF_NORMED) # Use cv2.matchTemplate() to search the image\n",
    "        min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)\n",
    "    \n",
    "        w, h = (tmp.shape[1], tmp.shape[0])\n",
    "        top_left = max_loc\n",
    "        bottom_right = (top_left[0] + w, top_left[1] + h)\n",
    "        bbox_list.append((top_left, bottom_right))\n",
    "\n",
    "    # Use cv2.minMaxLoc() to extract the location of the best match\n",
    "    # Determine bounding box corners for the match\n",
    "    # Return the list of bounding boxes\n",
    "    return bbox_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_dataset(normalize=True, smallset=False):\n",
    "    cars_path = 'dataset/vehicles/all/*.*'\n",
    "    notcars_path = 'dataset/non-vehicles/all/*.*'\n",
    "    \n",
    "    if smallset == True:\n",
    "        cars_path = 'dataset/cars-small/all/*.*'\n",
    "        notcars_path = 'dataset/notcars-small/all/*.*'\n",
    "    \n",
    "    gl_cars = glob.glob(cars_path)\n",
    "    gl_notcars = glob.glob(notcars_path)\n",
    "    cars = []\n",
    "    notcars = []\n",
    "\n",
    "    for image in gl_cars:\n",
    "        cars.append(image)\n",
    "\n",
    "    for image in gl_notcars:\n",
    "        notcars.append(image)\n",
    "\n",
    "    if normalize == True:\n",
    "        #keep cars and not cars lists with the same size\n",
    "        len_cars = len(cars)\n",
    "        len_notcars = len(notcars)\n",
    "\n",
    "        if len_cars > len_notcars:\n",
    "            for i in range(len_notcars, len_cars):\n",
    "                rand = random.randint(0,len_notcars)\n",
    "                image = notcars[rand]\n",
    "                notcars.append(image)\n",
    "        elif len_cars < len_notcars:\n",
    "            for i in range(len_cars, len_notcars):\n",
    "                rand = random.randint(0,len_cars)\n",
    "                image = cars[rand]\n",
    "                cars.append(image)\n",
    "    \n",
    "    return cars, notcars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_pipeline(color_spaces=[], normalize=True, smallset=False):\n",
    "    #read dataset\n",
    "    cars, notcars = read_dataset() #normalize, smallset)\n",
    "    \n",
    "    if len(color_spaces) == 0:\n",
    "        color_spaces = [\"RGB\", \"HSV\", \"LUV\", \"HLS\", \"YUV\", \"YCrCb\"]\n",
    "    \n",
    "    for color_space in color_spaces:\n",
    "        #extract features\n",
    "        car_features = uf.extract_features(cars, color_space=color_space, \n",
    "                            spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                            orient=orient, pix_per_cell=pix_per_cell, \n",
    "                            cell_per_block=cell_per_block, \n",
    "                            hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                            hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "        notcar_features = uf.extract_features(notcars, color_space=color_space, \n",
    "                                spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                                orient=orient, pix_per_cell=pix_per_cell, \n",
    "                                cell_per_block=cell_per_block, \n",
    "                                hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                                hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "\n",
    "        X = np.vstack((car_features, notcar_features)).astype(np.float64)\n",
    "        X_scaler = StandardScaler().fit(X) # Fit a per-column scaler\n",
    "        scaled_X = X_scaler.transform(X) # Apply the scaler to X\n",
    "        y = np.hstack((np.ones(len(car_features)), np.zeros(len(notcar_features)))) # Define the labels vector\n",
    "\n",
    "        #define train set\n",
    "        rand_state = np.random.randint(0, 100)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(scaled_X, y, test_size=0.2, random_state=rand_state)\n",
    "\n",
    "        # Use a linear SVC \n",
    "        svc = LinearSVC()\n",
    "        t=time.time()\n",
    "        svc.fit(X_train, y_train)\n",
    "        t2 = time.time()\n",
    "    \n",
    "        svc_filename = \"svc-\" + color_space + \".pkl\"\n",
    "        xscaler_filename = \"xscaler-\" + color_space + \".pkl\"\n",
    "    \n",
    "        #save svc and x_scaler\n",
    "        joblib.dump(svc, (\"save-training/\" + svc_filename))\n",
    "        joblib.dump(X_scaler, (\"save-training/\" + xscaler_filename))\n",
    "        \n",
    "        print(color_space)\n",
    "        print(round(t2-t, 2), 'Seconds to train SVC...')\n",
    "        print('Test Accuracy of SVC = ', round(svc.score(X_test, y_test), 4))\n",
    "        print(\"----\")\n",
    "        \n",
    "#0.9763 RGB\n",
    "#0.9892 HLS\n",
    "#0.9892 LUV\n",
    "#0.9871 LAB\n",
    "#0.9871 HSV\n",
    "#0.9914 YUV - 0.9957 (8 HIST_BIN) - 0.9935 (16 HIST_BIN) - (1.0 9ori, 8hist)\n",
    "#0.9871 YCrCb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def window_pipeline(img):\n",
    "    image = img[CONST_CROP_X1:CONST_CROP_X2, CONST_CROP_Y1:CONST_CROP_Y2]\n",
    "    draw_image = np.copy(image)\n",
    "    all_windows = []\n",
    "    i = 1\n",
    "    \n",
    "    for color_space in color_spaces:\n",
    "        svc_filename = \"save-training/svc-\" + color_space + \".pkl\"\n",
    "        xscaler_filename = \"save-training/xscaler-\" + color_space + \".pkl\"\n",
    "        \n",
    "        svc = joblib.load(svc_filename)\n",
    "        X_scaler = joblib.load(xscaler_filename)\n",
    "        \n",
    "        windows = uw.slide_window(image, x_start_stop=[None, None], y_start_stop=y_start_stop, \n",
    "                            xy_window=(64, 64), xy_overlap=(0.5, 0.5))\n",
    "\n",
    "        hot_windows = uw.search_windows(image, windows, svc, X_scaler, color_space=color_space, \n",
    "                                spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                                orient=orient, pix_per_cell=pix_per_cell, \n",
    "                                cell_per_block=cell_per_block, \n",
    "                                hog_channel=hog_channel, spatial_feat=True, \n",
    "                                hist_feat=True, hog_feat=True)\n",
    "        \n",
    "        all_windows = all_windows + hot_windows\n",
    "        \n",
    "        draw_image = draw_boxes(draw_image, hot_windows, color=(40*i, (40*i), 40*i), thick=2)\n",
    "        i += 1\n",
    "    \n",
    "    window_img = img.copy()\n",
    "    window_img[CONST_CROP_X1:CONST_CROP_X2, CONST_CROP_Y1:CONST_CROP_Y2] = draw_image\n",
    "\n",
    "    return window_img, all_windows\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def heat_pipeline(img, hot_windows, heat_thresh=2):\n",
    "    image = img[CONST_CROP_X1:CONST_CROP_X2, CONST_CROP_Y1:CONST_CROP_Y2]\n",
    "    heat = np.zeros_like(image[:,:,0]).astype(np.float)\n",
    "\n",
    "    # Add heat to each box in box list\n",
    "    heat = uh.add_heat(heat, hot_windows) #box_list)\n",
    "\n",
    "    # Apply threshold to help remove false positives\n",
    "    heat = uh.apply_threshold(heat, heat_thresh)\n",
    "\n",
    "    # Visualize the heatmap when displaying    \n",
    "    heatmap = np.clip(heat, 0, 255)\n",
    "\n",
    "    # Find final boxes from heatmap using label function\n",
    "    labels = label(heatmap)\n",
    "    draw_img = uh.draw_labeled_bboxes(np.copy(image), labels)\n",
    "    \n",
    "    heat_img = img.copy()\n",
    "    heat_img[CONST_CROP_X1:CONST_CROP_X2, CONST_CROP_Y1:CONST_CROP_Y2] = draw_img\n",
    "    \n",
    "    heat_map = np.zeros_like(img[:,:,0]).astype(np.float)\n",
    "    heat_map[CONST_CROP_X1:CONST_CROP_X2, CONST_CROP_Y1:CONST_CROP_Y2] = heatmap\n",
    "    \n",
    "    return heat_img, heat_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(img):\n",
    "    window_img, hot_windows = window_pipeline(img)\n",
    "    heat_img, heatmap = heat_pipeline(img, hot_windows)\n",
    "\n",
    "    return window_img, heat_img\n",
    "\n",
    "print('Pipeline OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_name = 'test_images/test1.jpg'\n",
    "image = mpimg.imread(img_name)\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_img = image[CONST_CROP_X1:CONST_CROP_X2, CONST_CROP_Y1:CONST_CROP_Y2]\n",
    "original_img = image.copy()\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.imshow(crop_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add random bounding boxes\n",
    "bboxes = [((100, 100), (200, 200)), ((1000, 100), (1100, 200))]\n",
    "result = draw_boxes(crop_img, bboxes)\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.imshow(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in car and non-car images\n",
    "cars, notcars = read_dataset(normalize=False, smallset=False)\n",
    "print(len(cars), len(notcars))\n",
    "\n",
    "cars, notcars = read_dataset(normalize=True, smallset=False)\n",
    "print(len(cars), len(notcars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pipeline(color_spaces, True, False)\n",
    "print('OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#color_spaces = [\"HSV\", \"YCrCb\", \"YUV\"]\n",
    "final_img, hot_windows = window_pipeline(original_img)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(final_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heat_img, heatmap = heat_pipeline(original_img, hot_windows, heat_thresh=2)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(heatmap)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(heat_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_img, hot_img = pipeline(original_img)\n",
    "\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "plt.subplot(121)\n",
    "plt.imshow(window_img)\n",
    "plt.subplot(122)\n",
    "plt.imshow(hot_img, cmap='hot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "img = original_img.copy() #mpimg.imread('test_image.jpg')\n",
    "\n",
    "ystart = 400\n",
    "ystop = 656\n",
    "scale = 1 #1.5\n",
    "    \n",
    "out_img = ufc.find_cars(img, ystart, ystop, scale, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(out_img)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on Videos\n",
    "\n",
    "You know what's cooler than drawing lanes over images? Drawing lanes over video!\n",
    "\n",
    "Provided videos: `project_video.mp4`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play the video inline, or if you prefer find the video in your filesystem (should be in the same directory) and play it in your video player of choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try the one with the solid white lane on the right first ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "##clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\").subclip(0,5)\n",
    "\n",
    "pp_hist = False\n",
    "video_output = 'output_test_video.mp4'\n",
    "clip1 = VideoFileClip(\"test_video.mp4\")\n",
    "white_clip = clip1.fl_image(pipeline).subclip(0,1) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(video_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(video_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Optional Challenge\n",
    "\n",
    "Challenge the others videos.\n",
    "`challenge_video.mp4`\n",
    "`hard_challenge_video.mp4`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
